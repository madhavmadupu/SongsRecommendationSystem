{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'LALA':\n",
      "853                      Nos Comemos (feat. Ozuna)\n",
      "196                                  Es un Secreto\n",
      "525                One Right Now (with The Weeknd)\n",
      "361    I Like You (A Happier Song) (with Doja Cat)\n",
      "375                                    Besos Moja2\n",
      "Name: track_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('./spotify-2023.csv', encoding='iso-8859-1')\n",
    "\n",
    "numerical_columns = ['bpm', 'danceability_%', 'valence_%', 'energy_%',\n",
    "                     'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
    "\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['track_name_encoded'] = label_encoder.fit_transform(df['track_name'])\n",
    "df['artist_name_encoded'] = label_encoder.fit_transform(df['artist(s)_name'])\n",
    "\n",
    "columns_for_similarity = numerical_columns + ['track_name_encoded', 'artist_name_encoded']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[columns_for_similarity] = scaler.fit_transform(df[columns_for_similarity])\n",
    "\n",
    "cosine_sim = cosine_similarity(df[columns_for_similarity])\n",
    "\n",
    "def get_song_recommendations(song_index, similarity_matrix, num_recommendations=5):\n",
    "    sim_scores = list(enumerate(similarity_matrix[song_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_similar_song_indices = [x[0] for x in sim_scores[1:num_recommendations+1]]\n",
    "    return df.iloc[top_similar_song_indices]['track_name']\n",
    "\n",
    "song_index = 1\n",
    "recommendations = get_song_recommendations(song_index, cosine_sim)\n",
    "print(f\"Recommendations for '{df.iloc[song_index]['track_name']}':\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 7250-7251: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\madhavmadupu\\Desktop\\ML_Projects\\SongsRecommendationSystem\\SongsRecommendationSystem.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler, LabelEncoder\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./spotify-2023.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# Replace 'your_data.csv' with your file path\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Preprocessing steps (similar to the previous code)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Encoding categorical columns: 'track_name' and 'artist(s)_name'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/madhavmadupu/Desktop/ML_Projects/SongsRecommendationSystem/SongsRecommendationSystem.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32mc:\\Users\\madhavmadupu\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\madhavmadupu\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\madhavmadupu\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\madhavmadupu\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\madhavmadupu\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:579\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2050\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 7250-7251: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./spotify-2023.csv', encoding='iso-8859-1')  # Replace 'your_data.csv' with your file path\n",
    "\n",
    "# Preprocessing steps (similar to the previous code)\n",
    "\n",
    "# Encoding categorical columns: 'track_name' and 'artist(s)_name'\n",
    "label_encoder = LabelEncoder()\n",
    "df['track_name_encoded'] = label_encoder.fit_transform(df['track_name'])\n",
    "df['artist_name_encoded'] = label_encoder.fit_transform(df['artist(s)_name'])\n",
    "\n",
    "columns_for_similarity = [\n",
    "    'bpm', 'danceability_%', 'valence_%', 'energy_%',\n",
    "    'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%',\n",
    "    'track_name_encoded', 'artist_name_encoded'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[columns_for_similarity] = scaler.fit_transform(df[columns_for_similarity])\n",
    "\n",
    "cosine_sim = cosine_similarity(df[columns_for_similarity])\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Song Recommender')\n",
    "\n",
    "selected_song = st.sidebar.selectbox('Select a Song', df['track_name'].values)\n",
    "\n",
    "# Get index of selected song\n",
    "song_index = df[df['track_name'] == selected_song].index[0]\n",
    "\n",
    "# Function to get song recommendations based on cosine similarity\n",
    "def get_song_recommendations(song_index, similarity_matrix, num_recommendations=5):\n",
    "    sim_scores = list(enumerate(similarity_matrix[song_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_similar_song_indices = [x[0] for x in sim_scores[1:num_recommendations+1]]\n",
    "    return df.iloc[top_similar_song_indices]\n",
    "\n",
    "if st.button('Show Recommendations'):\n",
    "    recommendations = get_song_recommendations(song_index, cosine_sim)\n",
    "    st.write(\"Recommendations for\", selected_song)\n",
    "    st.dataframe(recommendations[['track_name', 'artist(s)_name', 'streams']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
